{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad79862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import time\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386c9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    for punct in string.punctuation:\n",
    "        text = text.replace(punct, ' '+punct+' ')\n",
    "    t = text.split()\n",
    "    return t\n",
    "\n",
    "def get_ngrams(n: int, tokens: list) -> list:\n",
    "    tokens = (n-1)*['<START>']+tokens\n",
    "    l = [(tuple([tokens[i-p-1] for p in reversed(range(n-1))]), tokens[i]) for i in range(n-1, len(tokens))]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac719d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModel(object):\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.context = {}\n",
    "        self.ngram_counter = {}\n",
    "\n",
    "    def update(self, sentence: str) -> None:\n",
    "        n = self.n\n",
    "        ngrams = get_ngrams(n, tokenize(sentence))\n",
    "        for ngram in ngrams:\n",
    "            if ngram in self.ngram_counter:\n",
    "                self.ngram_counter[ngram] += 1.0\n",
    "            else:\n",
    "                self.ngram_counter[ngram] = 1.0\n",
    "\n",
    "            prev_words, target_word = ngram\n",
    "            if prev_words in self.context:\n",
    "                self.context[prev_words].append(target_word)\n",
    "            else:\n",
    "                self.context[prev_words] = [target_word]\n",
    "                \n",
    "    def freq(self, context, token):\n",
    "        try:\n",
    "            count_of_token = self.ngram_counter[(context, token)]\n",
    "            count_of_context = float(len(self.context[context]))\n",
    "            result = count_of_token / count_of_context\n",
    "\n",
    "        except KeyError:\n",
    "            result = 0.0\n",
    "        return result\n",
    "\n",
    "    def random_token(self, context):\n",
    "        r = random.random()\n",
    "        map_to_probs = {}\n",
    "        token_of_interest = self.context[context]\n",
    "        for token in token_of_interest:\n",
    "            map_to_probs[token] = self.freq(context, token)\n",
    "\n",
    "        summ = 0\n",
    "        for token in sorted(map_to_probs):\n",
    "            summ += map_to_probs[token]\n",
    "            if summ > r:\n",
    "                return token\n",
    "\n",
    "    def generate_text(self, token_count: int):\n",
    "        n = self.n\n",
    "        context_queue = (n - 1) * ['<START>']\n",
    "        result = []\n",
    "        for _ in range(token_count):\n",
    "            obj = self.random_token(tuple(context_queue))\n",
    "            result.append(obj)\n",
    "            if n > 1:\n",
    "                context_queue.pop(0)\n",
    "                if obj == '.':\n",
    "                    context_queue = (n - 1) * ['<START>']\n",
    "                else:\n",
    "                    context_queue.append(obj)\n",
    "        return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6e99e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_model(n, path):\n",
    "    m = NgramModel(n)\n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        text = text.split('.')\n",
    "        for sentence in text:\n",
    "            # add back the fullstop\n",
    "            sentence += '.'\n",
    "            m.update(sentence)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8090a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.8084056377410889\n",
      "Generated text:daily blog post - if not a lot , i ( 16 ? what actually comply ? why is he ’ d so hats , and harry potter and no one how much . . a previous minister against naggaroth in fact that tar and never hungout with tana and you all make the children ? ) in the numbers support ethnic cleansing . it is the waterfall meme pretending to replicate their wounded merchant account and ready , i can be a seeker , but i ’ ll give the time to the fancy dress . this works . 7 , but it say anything ! good enough so you roll in solo laners . to spare the sheikah quest for a patch ) , but good diet , $ 1000 . first , to offer . any hate her . the youngest is kinda driving and his dream not arnold . which is about my ` assault weapons such as currently doing a serial killers they do is the worst teams that was same bed and i ' ' ll cut the weirdest phase one ’ ve ever breaks down . ` from trying to jail time to attack or use the room before anyone to find that ’ s going to say ` ` ` the silver / snoopy vs menace ( i believe , you perceive me up for these stop before dropping and explains things aside from a tubo evic . it ’ s true damage from never a jlt team ' t bother saying that my favorite moments in the bldg started flushing began to lagging or some time for pugs are no pill . i know you said uber what do our upvoting party - 2018 draft , but before the screen tvs and she struggled against the wings . while i like érikav . 2 and listened to cast gets streaky when profit . * - march 28 , you think you a druid , t even better for two tickets > 2 turrets and screwing sxm . not have a waffle towel then . the backwardness of my finances are you cock carousel to cut and compensate . ] bmds / reinforcement . i cant farm ( actual 100 forma zephyr / iamverybadass oh , the knees doing things got my parents your finances in the past fall from 58k . . quick change ? ? what would n ' ford escape from alfonse , but would you level . yay ! deep , green earth and do n ' incredibles 2 acc , 2018 ] ] lf1m nightfall normal monster reborn ” gordon leaps for adoption guys know , then why it was switching attachments on our son was that or two polish to convince an amazing body . the next thing is real life ! sorry just know shit no , since i . at the day it ’ s funeral ? should n ' s a century and\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    m = create_ngram_model(2, 'reddit.txt')\n",
    "    print (f'Time taken: {time.time() - start}')\n",
    "    start = time.time()\n",
    "    random.seed(7)\n",
    "    x = m.generate_text(500)\n",
    "    print(f'Generated text:'+ x)\n",
    "    print(m.generate_text(500))\n",
    "    print(m.generate_text(500),file=open(\"reddit.out\", \"a\", encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74958871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 12.540882349014282\n",
      "Generated text:finally , the behavioral level and at the axon end - - in the brain . s . now , you ' ve described , and in the congo and other hydrocarbons as part of it as a great model : if you prick us , in their own country since . i think a lot . so this is true - - only on that show you is that , that people would say , ` ` aesop ' s a bit of a doughnut : 16 vertices covered by transparency laws . but it ' s what happened . at its heart . but , just getting started on the other person being touched by the way to go from ` ` bad ' ' and i ' ' and even if computers missed something , but incorporating genomics into what you do n ' t have any sexual activity , you heat hydrogen up - - you name it , but forms a lot of legs , three years of teaching us to create good jobs , and i can say whatever the technology world , despite cybercrime conventions , and the truth looks like many others , of the story of me - - he was with great ideas that strike us as a trek to the students would pose questions to ask , why is that when the thing that could be brought down global capitalism . and what i do n ' t want to learn how little that ' ll see a lot of people behind my head on , keeping in mind that it has the tag in it . it is i have more tools to translate this ancient river of trash , 15 minutes , but another task is to come to the clock to the earlier you intervene ? it seems highly unlikely that phenethylamine will reach the all - important , because the molecule , would we want and from a small democratic country . we saw economic despair , in the balloon , release it , with so much . this ended up in just a thing . and so hard , and approach a group of prop crazies just like laurel ♫ ♫ a silver lining . it was a suicide bomber does get a little lamb whose fleece was white as snow , and fortunately , there ' s a ted talk because , clearly at some of the equatorial zone , it ' s different and a half hours in advance ; we already had a before and after a procedure that was pretty nervous to give out your calculators , the area out . s . there ' s kind of starbucks tour of the reasons why if you ' re always there for some reason i have , they said , ` ` be obscure clearly ! be wild dogs living there . i have some relevance to performing a behavior called\n",
      "that ' s 3d , dynamic people - - every scrap of paper , tons of wild salmon . in the world . but i went down the door and we ' ve got to say , tickle me elmo - - is i ' m going to - one step ahead of time to fight climate change world that i fully and viscerally grasped the importance of detailed , realistic computer - readable text so that when you invite them all the other side of nature ' s a lot of interruptions by these feelings make me happy . and i asked this question . we would have been breeding the flowers , but i know when you get into that egg . a few years , it has to be asking ourselves , how when you think , ` ` where did this , he weighs 300 pounds now . and how possible this is the part that i imagined . the fact that there are about 35 percent of bike lanes . now , how many 15 - to try to suppress the dopamine and being persuaded . ' ' or ` ` tall horse , ' ' contest a few weeks later , first you have to consider and measure how you get a different method for qualifying a team at the center , ames research center in the year was graded . well , america had gone on his couch , folded objects that await us if we take them off , imagine if you are constructed . ' ' that pollution . ' ' we buy stock ? and i will not be scared of it ' s two really thorny sets of lectures where , for example , most school districts spend two to three or four fully trained ph . and they are . ' ' and you should use a catheter bottle . so in contrast , the play scene . so , we can make fish sticks that you ca n ' t happen accidentally . it ' s now your 21st century is their story , because he believed we live our lives may have broken out of an idea of conscience . and i can play shiritori as you can see across all five of them , and joy and marvel at , sometime between midnight and you can put it in the year 2000 , the density - - in the invasion of iraq - - needed reforms . and the images kind of disease . we ' re showing your true colors of war . ` ` is this large scale , the dolphins choice and was built around online crime . and i think we ' re really a thought - balloon , ready ? go figure . so in nepal , the main drivers behind less violent - - and also i ' m initiating at the bi - species jump , he had\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    m = create_ngram_model(3, 'ted.txt')\n",
    "\n",
    "    print (f'Time taken: {time.time() - start}')\n",
    "    start = time.time()\n",
    "    random.seed(7)\n",
    "    x = m.generate_text(500)\n",
    "    print(f'Generated text:'+ x)\n",
    "    print(m.generate_text(500))\n",
    "    print(m.generate_text(500),file=open(\"ted.out\", \"a\", encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da54376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
